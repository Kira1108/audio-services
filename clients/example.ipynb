{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Automatic Speech Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.asr.offline import ParaformerOffline\n",
    "\n",
    "paraformer = ParaformerOffline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paraformer.model\n",
    "import soundfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file = '/data1/wanghuan/audio_services/cache/asr_example.wav'\n",
    "speech, _ = soundfile.read(wav_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rtf_avg: 0.108: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.83it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rtf_avg: -0.017: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 44.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rtf_avg: 0.107, time_speech:  5.547, time_escape: 0.591: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'key': 'rand_key_EefRWi4j7c1f5',\n",
       "  'text': '欢迎大家来体验达摩院推出的语音识别模型。',\n",
       "  'timestamp': [[880, 1120],\n",
       "   [1120, 1360],\n",
       "   [1380, 1540],\n",
       "   [1540, 1780],\n",
       "   [1780, 2020],\n",
       "   [2020, 2180],\n",
       "   [2180, 2420],\n",
       "   [2480, 2600],\n",
       "   [2600, 2780],\n",
       "   [2780, 3020],\n",
       "   [3040, 3240],\n",
       "   [3240, 3480],\n",
       "   [3480, 3700],\n",
       "   [3700, 3900],\n",
       "   [3900, 4140],\n",
       "   [4180, 4420],\n",
       "   [4420, 4620],\n",
       "   [4620, 4780],\n",
       "   [4780, 5195]]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.127: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 15.60it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_1qeoePtwBldGD', 'text': ''}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.101: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.49it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_cMgSzmqw5UE15', 'text': ''}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.144: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.78it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_6KkSRn9XdYRk2', 'text': '欢'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.135: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.82it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_kvHqhM6CQlaER', 'text': '迎大'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.135: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.69it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_A5K3G6tPwy1Qq', 'text': '家来体'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.132: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 15.18it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_jJSaDVfvVcIri', 'text': '验达'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.132: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 15.23it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_pW9EwNsRwL85O', 'text': '摩院'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.127: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 15.60it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2NiTtyVA1PfaM', 'text': '推出'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.146: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.47it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_mSvkpoOCyT4RK', 'text': '的语'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.140: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.97it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_3Acz3SKAXQTck', 'text': '音识'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.49it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_CeqSkCH4F6JMW', 'text': '别模'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.261: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.24it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_a4cFut1DdZ04Z', 'text': '型'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from app.asr import ParaformerStreaming\n",
    "\n",
    "import soundfile\n",
    "    \n",
    "chunk_ms = 480\n",
    "sampling_rate = 16000\n",
    "chunk_frames = int(chunk_ms * sampling_rate / 1000)\n",
    "\n",
    "p = ParaformerStreaming(\n",
    "    chunk_ms = chunk_ms)\n",
    "\n",
    "wav_file = '/data1/wanghuan/audio_services/cache/asr_example.wav'\n",
    "speech, _ = soundfile.read(wav_file)\n",
    "\n",
    "total_chunk_num = int(len((speech)-1)/chunk_frames+1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_frames:(i+1)*chunk_frames]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = p.run(speech_chunk, sampling_rate=sampling_rate, is_final = is_final)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voice Activity Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 17:13:33,640 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.381: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.89it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 126.40it/s]                                                                                          \n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 114.92it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 135.38it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 132.22it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 127.57it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 130.88it/s]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 118.84it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 145.73it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 151.84it/s]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 124.58it/s]                                                                                          \n",
      "rtf_avg: 0.575: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 72.74it/s]                                                                                          \n"
     ]
    }
   ],
   "source": [
    "from app.vad import FMSNVad\n",
    "import soundfile\n",
    "\n",
    "chunk_seconds = 480\n",
    "\n",
    "audio_data, sampling_rate = soundfile.read(\"/data1/wanghuan/audio_services/cache/asr_example.wav\")\n",
    "vad = FMSNVad()\n",
    "\n",
    "\n",
    "wav_file = f\"/data1/wanghuan/audio_services/cache/asr_example.wav\"\n",
    "speech, sample_rate = soundfile.read(wav_file)\n",
    "chunk_stride = int(chunk_seconds * sample_rate / 1000)\n",
    "\n",
    "results = []\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)\n",
    "for i in range(total_chunk_num):\n",
    "    if i == total_chunk_num -1:\n",
    "        is_final = True\n",
    "    else:\n",
    "        is_final = False\n",
    "    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n",
    "    res = vad.run(speech_chunk, is_final = is_final)\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'key': 'rand_key_2yW4Acq9GFz6Y', 'value': []}],\n",
       " [{'key': 'rand_key_1t9EwL56nGisi', 'value': []}],\n",
       " [{'key': 'rand_key_WgNZq6ITZM5jt', 'value': [[610, -1]]}],\n",
       " [{'key': 'rand_key_gUe52RvEJgwBu', 'value': []}],\n",
       " [{'key': 'rand_key_NO6n9JEC3HqdZ', 'value': []}],\n",
       " [{'key': 'rand_key_6J6afU1zT0YQO', 'value': []}],\n",
       " [{'key': 'rand_key_aNF03vpUuT3em', 'value': []}],\n",
       " [{'key': 'rand_key_6KopZ9jZICffu', 'value': []}],\n",
       " [{'key': 'rand_key_4G7FgtJsThJv0', 'value': []}],\n",
       " [{'key': 'rand_key_7In9ZMJLsCfMZ', 'value': []}],\n",
       " [{'key': 'rand_key_yuKpslm0lcNQq', 'value': []}],\n",
       " [{'key': 'rand_key_EefRWi4j7c1f5', 'value': [[-1, 5530]]}]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.100: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 16.03it/s]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 101.73it/s]                                                                                          \n",
      "rtf_avg: 0.093: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 17.06it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.77it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.08it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.26it/s]                                                                                          \n",
      "rtf_avg: 0.127: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.68it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.75it/s]                                                                                          \n",
      "rtf_avg: 0.095: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 16.81it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.42it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好你好\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.21it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.72it/s]                                                                                          \n",
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.26it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.62it/s]                                                                                          \n",
      "rtf_avg: 0.120: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.48it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 117.47it/s]                                                                                          \n",
      "rtf_avg: 0.091: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 17.50it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.01it/s]                                                                                          \n",
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.26it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 118.37it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.15it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 114.64it/s]                                                                                          \n",
      "rtf_avg: 0.121: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.36it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 119.84it/s]                                                                                          \n",
      "rtf_avg: 0.092: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 17.40it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.64it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天你开心吗你们公司有什么产品\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.27it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.24it/s]                                                                                          \n",
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.27it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 117.87it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.64it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 119.91it/s]                                                                                          \n",
      "rtf_avg: 0.228: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.02it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你们公司是做金融的吗\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from app.asr import ParaformerStreaming\n",
    "from app.vad import FMSNVad\n",
    "import soundfile\n",
    "    \n",
    "chunk_ms = 600\n",
    "sampling_rate = 16000\n",
    "chunk_frames = int(chunk_ms * sampling_rate / 1000)\n",
    "\n",
    "p = ParaformerStreaming(\n",
    "    chunk_ms = chunk_ms)\n",
    "\n",
    "vad = FMSNVad()\n",
    "\n",
    "wav_file = '/data1/wanghuan/audio_services/cache/recording.wav'\n",
    "speech, _ = soundfile.read(wav_file)\n",
    "\n",
    "stream_cache = []\n",
    "cache = []\n",
    "total_chunk_num = int(len((speech)-1)/chunk_frames+1)\n",
    "\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_frames:(i+1)*chunk_frames]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = p.run(speech_chunk, sampling_rate=sampling_rate, is_final = is_final)\n",
    "    cache.append(res)\n",
    "    stream_cache.append(res)\n",
    "    \n",
    "    if vad.vad(speech_chunk, sample_rate = sampling_rate, is_final = is_final):\n",
    "        t = [v[0]['text'] for v in cache]\n",
    "        print(\"\".join(t))\n",
    "        cache = []\n",
    "        \n",
    "if len(cache) > 0:\n",
    "    t = [v[0]['text'] for v in cache]       \n",
    "    print(\"\".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funasr import AutoModel\n",
    "from functools import lru_cache\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_punc_model():\n",
    "    return AutoModel(model=\"ct-punc\", model_revision=\"v2.0.4\")\n",
    "\n",
    "@dataclass\n",
    "class PunctuationModel:\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.model = load_punc_model()\n",
    "        \n",
    "    def run(self, text:str):\n",
    "        return self.model.generate(input=text)[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import soundfile\n",
    "from app.asr import ParaformerStreaming\n",
    "from app.vad import FMSNVad\n",
    "\n",
    "@dataclass\n",
    "class AudioInputPipeline:\n",
    "    \n",
    "    chunk_ms: int = 600\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.vad = FMSNVad()\n",
    "        self.asr = ParaformerStreaming(chunk_ms=chunk_ms)\n",
    "        self.punc_model = PunctuationModel()\n",
    "        self.stream_cache = []\n",
    "        self.temp_cache = []\n",
    "        self.chunk_id = 0\n",
    "        \n",
    "    def parse(\n",
    "        self, \n",
    "        speech_chunk, \n",
    "        sampling_rate = 16000, \n",
    "        is_final = False):\n",
    "        \n",
    "        asr_result = self.asr.run(\n",
    "            speech_chunk, \n",
    "            sampling_rate=sampling_rate, \n",
    "            is_final = is_final)\n",
    "        \n",
    "        # vad缓存\n",
    "        self.temp_cache.append(asr_result)\n",
    "        \n",
    "        # 整体缓存\n",
    "        self.stream_cache.append(asr_result)\n",
    "        \n",
    "        if self.vad.vad(\n",
    "            speech_chunk, \n",
    "            sample_rate = sampling_rate, \n",
    "            is_final = is_final):\n",
    "            \n",
    "            t = [v[0]['text'] for v in self.temp_cache]\n",
    "            output = \"\".join(t)\n",
    "            # 重置vad缓存\n",
    "            self.temp_cache = []\n",
    "            return self.punc_model.run(output)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 20:49:51,667 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 20:49:53,111 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 20:49:58,478 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.619 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.619 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "from app.pipeline.audio_input_pipe import AudioInputPipeline\n",
    "pipe = AudioInputPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.222: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.85it/s]                                                                                          \n",
      "rtf_avg: 0.265: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  6.21it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=1 start_time=0 end_time=600 text='' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.010: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 144.98it/s]                                                                                          \n",
      "rtf_avg: 0.063: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 24.85it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=2 start_time=600 end_time=1200 text='' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 161.36it/s]                                                                                          \n",
      "rtf_avg: 0.097: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 16.82it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=3 start_time=1200 end_time=1800 text='你好你' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 149.77it/s]                                                                                          \n",
      "rtf_avg: 0.087: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 18.68it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=4 start_time=1800 end_time=2400 text='好' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 161.46it/s]                                                                                          \n",
      "rtf_avg: 0.063: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 25.40it/s]                                                                                          \n",
      "rtf_avg: -0.360: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.76it/s]                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=5 start_time=2400 end_time=3000 text='你好你好。' is_partial=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 138.83it/s]                                                                                          \n",
      "rtf_avg: 0.083: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.49it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=6 start_time=3000 end_time=3600 text='今' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 151.22it/s]                                                                                          \n",
      "rtf_avg: 0.083: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.42it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=7 start_time=3600 end_time=4200 text='天你开' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.007: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 171.75it/s]                                                                                          \n",
      "rtf_avg: 0.084: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.26it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=8 start_time=4200 end_time=4800 text='心吗' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 151.84it/s]                                                                                          \n",
      "rtf_avg: 0.063: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 25.38it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=9 start_time=4800 end_time=5400 text='' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 152.70it/s]                                                                                          \n",
      "rtf_avg: 0.084: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.21it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=10 start_time=5400 end_time=6000 text='你们公司有' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 156.55it/s]                                                                                          \n",
      "rtf_avg: 0.084: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.42it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=11 start_time=6000 end_time=6600 text='什么产' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.007: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 166.86it/s]                                                                                          \n",
      "rtf_avg: 0.082: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.51it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=12 start_time=6600 end_time=7200 text='品' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 145.88it/s]                                                                                          \n",
      "rtf_avg: 0.062: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 25.84it/s]                                                                                          \n",
      "rtf_avg: -0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 83.55it/s]                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=13 start_time=7200 end_time=7800 text='今天你开心吗？你们公司有什么产品？' is_partial=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 146.13it/s]                                                                                          \n",
      "rtf_avg: 0.082: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.76it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=14 start_time=7800 end_time=8400 text='你' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 155.32it/s]                                                                                          \n",
      "rtf_avg: 0.083: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.50it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=15 start_time=8400 end_time=9000 text='们公司是' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 159.64it/s]                                                                                          \n",
      "rtf_avg: 0.083: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.58it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=16 start_time=9000 end_time=9600 text='做金融' is_partial=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.164: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 19.83it/s]                                                                                          \n",
      "rtf_avg: -0.010: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 88.33it/s]                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出结果： conversation_id='555930b3-d8e8-4934-b78e-50f29f066178' chunk_id=17 start_time=9600 end_time=10200 text='你们公司是做金融的吗？' is_partial=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_ms = 600\n",
    "sampling_rate = 16000\n",
    "chunk_frames = int(chunk_ms * sampling_rate / 1000)\n",
    "\n",
    "wav_file = '/data1/wanghuan/audio_services/cache/recording.wav'\n",
    "speech, _ = soundfile.read(wav_file)\n",
    "chunk_stride = int(chunk_ms * sampling_rate / 1000)\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)\n",
    "\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_frames:(i+1)*chunk_frames]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = pipe.parse(speech_chunk, sampling_rate=sampling_rate, is_final = is_final)\n",
    "    print(\"输出结果：\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: success [0. 0. 0. 0. 0.]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 1, 'start_time': 0, 'end_time': 600, 'text': '', 'is_partial': True}\n",
      "Sent: success [0. 0. 0. 0. 0.]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 2, 'start_time': 600, 'end_time': 1200, 'text': '', 'is_partial': True}\n",
      "Sent: success [ 0.16900635  0.31655884 -0.48492432 -0.35516357  0.07397461]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 3, 'start_time': 1200, 'end_time': 1800, 'text': '你好你', 'is_partial': True}\n",
      "Sent: success [ 0.00326538  0.0012207  -0.00137329 -0.00039673  0.0005188 ]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 4, 'start_time': 1800, 'end_time': 2400, 'text': '好', 'is_partial': True}\n",
      "Sent: success [ 0.00030518  0.00024414 -0.00018311 -0.00021362  0.        ]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 5, 'start_time': 2400, 'end_time': 3000, 'text': '你好你好。。', 'is_partial': False}\n",
      "Sent: success [-6.10351562e-05 -9.15527344e-04 -1.15966797e-03  1.83105469e-04\n",
      "  6.71386719e-04]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 6, 'start_time': 3000, 'end_time': 3600, 'text': '今', 'is_partial': True}\n",
      "Sent: success [-0.00048828  0.01647949  0.00576782 -0.00958252 -0.00531006]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 7, 'start_time': 3600, 'end_time': 4200, 'text': '天你开心', 'is_partial': True}\n",
      "Sent: success [-0.00067139 -0.00360107  0.00018311  0.00256348 -0.00039673]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 8, 'start_time': 4200, 'end_time': 4800, 'text': '吗', 'is_partial': True}\n",
      "Sent: success [-6.10351562e-05 -3.05175781e-05 -9.15527344e-05 -6.10351562e-05\n",
      " -3.05175781e-05]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 9, 'start_time': 4800, 'end_time': 5400, 'text': '', 'is_partial': True}\n",
      "Sent: success [-0.1265564  -0.1144104  -0.11251831 -0.10583496 -0.08987427]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 10, 'start_time': 5400, 'end_time': 6000, 'text': '你们公司有', 'is_partial': True}\n",
      "Sent: success [-0.15853882 -0.11883545 -0.02658081  0.01052856  0.07543945]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 11, 'start_time': 6000, 'end_time': 6600, 'text': '什么产', 'is_partial': True}\n",
      "Sent: success [-0.00067139  0.          0.0007019   0.00094604  0.00045776]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 12, 'start_time': 6600, 'end_time': 7200, 'text': '品', 'is_partial': True}\n",
      "Sent: success [-3.05175781e-05 -6.10351562e-05 -6.10351562e-05  3.05175781e-05\n",
      "  6.10351562e-05]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 13, 'start_time': 7200, 'end_time': 7800, 'text': '今天你开心吗？？，你们公司有什么产品？？？', 'is_partial': False}\n",
      "Sent: success [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 3.05175781e-05]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 14, 'start_time': 7800, 'end_time': 8400, 'text': '你', 'is_partial': True}\n",
      "Sent: success [-0.01797485  0.01196289 -0.09912109 -0.01498413 -0.0055542 ]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 15, 'start_time': 8400, 'end_time': 9000, 'text': '们公司是', 'is_partial': True}\n",
      "Sent: success [-0.22946167 -0.16278076 -0.1008606  -0.06289673 -0.03915405]...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 16, 'start_time': 9000, 'end_time': 9600, 'text': '做金融', 'is_partial': True}\n",
      "Sent: success []...\n",
      "Received: {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 17, 'start_time': 9600, 'end_time': 10200, 'text': '你们公司是做金融的吗？？。', 'is_partial': False}\n",
      "Sent: {'status': 'end', 'chunk': []}\n",
      "Got result [{'action': 'start', 'timestamp': 1746008185.5657713}, {'action': 'send', 'timestamp': 1746008185.5691977}, {'action': 'receive', 'timestamp': 1746008185.6438673, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 1, 'start_time': 0, 'end_time': 600, 'text': '', 'is_partial': True}, 'text': '', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008185.6723485}, {'action': 'receive', 'timestamp': 1746008185.8917704, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 2, 'start_time': 600, 'end_time': 1200, 'text': '', 'is_partial': True}, 'text': '', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008185.9224598}, {'action': 'receive', 'timestamp': 1746008185.9927359, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 3, 'start_time': 1200, 'end_time': 1800, 'text': '你好你', 'is_partial': True}, 'text': '你好你', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008186.0207753}, {'action': 'receive', 'timestamp': 1746008186.2588902, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 4, 'start_time': 1800, 'end_time': 2400, 'text': '好', 'is_partial': True}, 'text': '好', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008186.2878537}, {'action': 'receive', 'timestamp': 1746008186.6943448, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 5, 'start_time': 2400, 'end_time': 3000, 'text': '你好你好。。', 'is_partial': False}, 'text': '你好你好。。', 'is_partial': False}, {'action': 'send', 'timestamp': 1746008186.7285166}, {'action': 'receive', 'timestamp': 1746008186.9364314, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 6, 'start_time': 3000, 'end_time': 3600, 'text': '今', 'is_partial': True}, 'text': '今', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008186.9709365}, {'action': 'receive', 'timestamp': 1746008187.034834, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 7, 'start_time': 3600, 'end_time': 4200, 'text': '天你开心', 'is_partial': True}, 'text': '天你开心', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.0587485}, {'action': 'receive', 'timestamp': 1746008187.1206753, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 8, 'start_time': 4200, 'end_time': 4800, 'text': '吗', 'is_partial': True}, 'text': '吗', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.1473634}, {'action': 'receive', 'timestamp': 1746008187.1977215, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 9, 'start_time': 4800, 'end_time': 5400, 'text': '', 'is_partial': True}, 'text': '', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.22625}, {'action': 'receive', 'timestamp': 1746008187.2887683, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 10, 'start_time': 5400, 'end_time': 6000, 'text': '你们公司有', 'is_partial': True}, 'text': '你们公司有', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.31586}, {'action': 'receive', 'timestamp': 1746008187.5461133, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 11, 'start_time': 6000, 'end_time': 6600, 'text': '什么产', 'is_partial': True}, 'text': '什么产', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.5623705}, {'action': 'receive', 'timestamp': 1746008187.62572, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 12, 'start_time': 6600, 'end_time': 7200, 'text': '品', 'is_partial': True}, 'text': '品', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008187.634668}, {'action': 'receive', 'timestamp': 1746008188.1994085, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 13, 'start_time': 7200, 'end_time': 7800, 'text': '今天你开心吗？？，你们公司有什么产品？？？', 'is_partial': False}, 'text': '今天你开心吗？？，你们公司有什么产品？？？', 'is_partial': False}, {'action': 'send', 'timestamp': 1746008188.2298355}, {'action': 'receive', 'timestamp': 1746008188.293647, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 14, 'start_time': 7800, 'end_time': 8400, 'text': '你', 'is_partial': True}, 'text': '你', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008188.3225043}, {'action': 'receive', 'timestamp': 1746008188.5271897, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 15, 'start_time': 8400, 'end_time': 9000, 'text': '们公司是', 'is_partial': True}, 'text': '们公司是', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008188.557341}, {'action': 'receive', 'timestamp': 1746008188.6220226, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 16, 'start_time': 9000, 'end_time': 9600, 'text': '做金融', 'is_partial': True}, 'text': '做金融', 'is_partial': True}, {'action': 'send', 'timestamp': 1746008188.6225555}, {'action': 'receive', 'timestamp': 1746008189.240077, 'data': {'conversation_id': '7d35dc8b-aabf-4825-9fb4-584fdb070c21', 'chunk_id': 17, 'start_time': 9600, 'end_time': 10200, 'text': '你们公司是做金融的吗？？。', 'is_partial': False}, 'text': '你们公司是做金融的吗？？。', 'is_partial': False}, {'action': 'end', 'timestamp': 1746008189.2401986}]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import websockets\n",
    "import json\n",
    "import soundfile\n",
    "import time\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def stream_asr(speech, chunk_frames:int = 9600):\n",
    "    uri = \"ws://localhost:7890/asr/streaming/pipeline\"\n",
    "    total_chunk_num = int(len((speech)-1)/chunk_frames+1)\n",
    "    \n",
    "    async with websockets.connect(uri) as websocket:\n",
    "        results = []\n",
    "        results.append({\"action\":\"start\", \"timestamp\":time.time()})\n",
    "        # 逐个发送每个chunk(音频流)的数据\n",
    "        for i in range(total_chunk_num):\n",
    "            speech_chunk = speech[i*chunk_frames:(i+1)*chunk_frames]\n",
    "            data = {\n",
    "                \"chunk\": speech_chunk.tolist(),\n",
    "                \"status\": \"processing\"\n",
    "            }\n",
    "            \n",
    "            is_final = i == total_chunk_num - 1\n",
    "            data.update({\"is_final\": is_final})\n",
    "            \n",
    "            # 发送数据\n",
    "            \n",
    "            await websocket.send(json.dumps(data))\n",
    "            results.append({\"action\":\"send\", \"timestamp\":time.time()})\n",
    "            print(f\"Sent: success {str(speech_chunk[:5])}...\")  # Print first 5 samples for brevity\n",
    "\n",
    "            response = await websocket.recv()\n",
    "            response = json.loads(response)\n",
    "            results.append(\n",
    "                {\"action\":\"receive\", \n",
    "                 \"timestamp\":time.time(), \n",
    "                 \"data\":response, \n",
    "                 \"text\": response.get(\"text\", \"\"), \n",
    "                 \"is_partial\":response.get(\"is_partial\", False)})\n",
    "            print(f\"Received: {response}\")\n",
    "        results.append({\"action\":\"end\", \"timestamp\":time.time()})\n",
    "        end_message = {\"status\": \"end\", \"chunk\": []}\n",
    "        await websocket.send(json.dumps(end_message))\n",
    "        print(f\"Sent: {end_message}\")\n",
    "    return results\n",
    "\n",
    "wav_file = '/data1/wanghuan/audio_services/cache/recording.wav'\n",
    "speech, _ = soundfile.read(wav_file)\n",
    "res = asyncio.run(stream_asr(speech))\n",
    "print('Got result', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df['duration'] = df['timestamp'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>data</th>\n",
       "      <th>text</th>\n",
       "      <th>is_partial</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0.074670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0.219422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>你好你</td>\n",
       "      <td>True</td>\n",
       "      <td>0.070276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>好</td>\n",
       "      <td>True</td>\n",
       "      <td>0.238115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>你好你好。。</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>今</td>\n",
       "      <td>True</td>\n",
       "      <td>0.207915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>天你开心</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>吗</td>\n",
       "      <td>True</td>\n",
       "      <td>0.061927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>0.050358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>你们公司有</td>\n",
       "      <td>True</td>\n",
       "      <td>0.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>什么产</td>\n",
       "      <td>True</td>\n",
       "      <td>0.230253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>品</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>今天你开心吗？？，你们公司有什么产品？？？</td>\n",
       "      <td>False</td>\n",
       "      <td>0.564740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>你</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>们公司是</td>\n",
       "      <td>True</td>\n",
       "      <td>0.204685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>做金融</td>\n",
       "      <td>True</td>\n",
       "      <td>0.064682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>receive</td>\n",
       "      <td>1.746008e+09</td>\n",
       "      <td>{'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...</td>\n",
       "      <td>你们公司是做金融的吗？？。</td>\n",
       "      <td>False</td>\n",
       "      <td>0.617522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     action     timestamp                                               data  \\\n",
       "2   receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "4   receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "6   receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "8   receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "10  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "12  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "14  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "16  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "18  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "20  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "22  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "24  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "26  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "28  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "30  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "32  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "34  receive  1.746008e+09  {'conversation_id': '7d35dc8b-aabf-4825-9fb4-5...   \n",
       "\n",
       "                     text is_partial  duration  \n",
       "2                               True  0.074670  \n",
       "4                               True  0.219422  \n",
       "6                     你好你       True  0.070276  \n",
       "8                       好       True  0.238115  \n",
       "10                 你好你好。。      False  0.406491  \n",
       "12                      今       True  0.207915  \n",
       "14                   天你开心       True  0.063897  \n",
       "16                      吗       True  0.061927  \n",
       "18                              True  0.050358  \n",
       "20                  你们公司有       True  0.062518  \n",
       "22                    什么产       True  0.230253  \n",
       "24                      品       True  0.063349  \n",
       "26  今天你开心吗？？，你们公司有什么产品？？？      False  0.564740  \n",
       "28                      你       True  0.063812  \n",
       "30                   们公司是       True  0.204685  \n",
       "32                    做金融       True  0.064682  \n",
       "34          你们公司是做金融的吗？？。      False  0.617522  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.action == \"receive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from app.asr import ParaformerStreaming\n",
    "from app.asr import ParaformerOffline\n",
    "from app.vad import FMSNVad\n",
    "from app.punctuations import PunctuationModel\n",
    "from app.schemas.core import ASRResult\n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class AudioInputPipeline:\n",
    "    \n",
    "    chunk_ms: int = 600\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.vad = FMSNVad()\n",
    "        self.asr = ParaformerStreaming(chunk_ms=self.chunk_ms)\n",
    "        self.offline = ParaformerOffline()\n",
    "        self.punc_model = PunctuationModel()\n",
    "        self.stream_cache = []\n",
    "        self.temp_cache = []\n",
    "        self.speech_cache = np.array([])\n",
    "        self.chunk_id = 0\n",
    "        self.conversation_id = str(uuid4())\n",
    "        \n",
    "    def parse(\n",
    "        self, \n",
    "        speech_chunk, \n",
    "        sampling_rate = 16000, \n",
    "        is_final = False):\n",
    "        \n",
    "        start_time = self.chunk_id *self.chunk_ms\n",
    "        end_time = (self.chunk_id + 1) * self.chunk_ms\n",
    "        \n",
    "        # 语音流缓存\n",
    "        speech_chunk = np.array(speech_chunk)\n",
    "        self.speech_cache = np.concatenate([self.speech_cache, speech_chunk], axis = 0)\n",
    "\n",
    "        vad_result = self.vad.vad(\n",
    "            speech_chunk, \n",
    "            sample_rate=sampling_rate, \n",
    "            is_final=is_final)\n",
    "        \n",
    "        complete_vad = vad_result or is_final\n",
    "        \n",
    "        if not complete_vad:\n",
    "            asr_result = self.asr.run(\n",
    "                speech_chunk, \n",
    "                sampling_rate=sampling_rate, \n",
    "                is_final = is_final)[0]['text']\n",
    "        else:\n",
    "            asr_result = self.offline.run(self.speech_cache)[0]['text']\n",
    "        \n",
    "        # 整体ASR流缓存\n",
    "        self.stream_cache.append(asr_result)\n",
    "        \n",
    "        if complete_vad:\n",
    "            # t = [v[0]['text'] for v in self.temp_cache]\n",
    "            # output = \"\".join(t)\n",
    "            # 重置vad缓存\n",
    "            self.speech_cache = np.array([])\n",
    "            self.temp_cache = []\n",
    "            output = self.punc_model.run(asr_result)\n",
    "            is_partial = False\n",
    "        else:\n",
    "            self.temp_cache.append(asr_result)\n",
    "            output = asr_result\n",
    "            is_partial = True\n",
    "            \n",
    "        res = ASRResult(\n",
    "            conversation_id=self.conversation_id,\n",
    "            chunk_id=self.chunk_id + 1,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            text=output,\n",
    "            is_partial=is_partial\n",
    "        )\n",
    "        \n",
    "        self.chunk_id += 1\n",
    "        \n",
    "        return res\n",
    "\n",
    "    \n",
    "    def parse_two_stage(self,\n",
    "        speech_chunk, \n",
    "        sampling_rate = 16000, \n",
    "        is_final = False):\n",
    "        \n",
    "        start_time = self.chunk_id *self.chunk_ms\n",
    "        end_time = (self.chunk_id + 1) * self.chunk_ms\n",
    "\n",
    "        vad_result = self.vad.vad(\n",
    "            speech_chunk, \n",
    "            sample_rate=sampling_rate, \n",
    "            is_final=is_final)\n",
    "        \n",
    "        \n",
    "        if vad_result or is_final:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioInputPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 16:21:09,847 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 91.29it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'value': [[70, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 99.63it/s]                                                                                           \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.06it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.72it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 101.52it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_NO6n9JEC3HqdZ', 'value': [[-1, 2340]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 95.47it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_6J6afU1zT0YQO', 'value': [[2620, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 100.14it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 106.41it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.25it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.05it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 106.80it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 106.78it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_EefRWi4j7c1f5', 'value': [[-1, 6200], [6480, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 101.39it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.73it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.49it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.37it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.01it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.72it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.54it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.73it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.30it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 106.67it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.42it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.89it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.70it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.46it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.99it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.99it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.24it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.09it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.13it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.49it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.68it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.89it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.78it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.49it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.94it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.57it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.45it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.63it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.23it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_vvYxTfvXNccrk', 'value': [[-1, 23670], [23950, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.85it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.48it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.56it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.70it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_hSFBctvVR5j6k', 'value': [[-1, 26250]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 98.13it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_OKyZOfeZfmVod', 'value': [[26780, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 97.30it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.27it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.12it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.36it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_hFzqnPc8ZnNjg', 'value': [[-1, 28990]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 94.20it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_mDyxI0jgMFjKz', 'value': [[29950, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 98.50it/s]                                                                                           \n",
      "rtf_avg: 0.016: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 76.33it/s]                                                                                           \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 99.58it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_5u0ucHj3qMYj1', 'value': [[-1, 31430], [31750, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 98.60it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.86it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.21it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.57it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.94it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.28it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.78it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 101.17it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.20it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.74it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_ZwAcNDyDdgEXj', 'value': [[-1, 37600]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 95.52it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_bcMNiOugSJPwm', 'value': [[38210, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 98.11it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.46it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.81it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.96it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.61it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.65it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 110.21it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 111.03it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.73it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 106.35it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.89it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.75it/s]                                                                                          \n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 85.72it/s]                                                                                           \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 90.75it/s]                                                                                           \n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 87.88it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_ILtky5j8iZouG', 'value': [[-1, 46900], [47310, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 96.81it/s]                                                                                           \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 93.61it/s]                                                                                           \n",
      "rtf_avg: 0.016: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 85.29it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 104.99it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_yAaA9U5uCnxs8', 'value': [[-1, 49630], [49910, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.016: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 83.04it/s]                                                                                           \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 96.48it/s]                                                                                           \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 94.41it/s]                                                                                           \n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 89.81it/s]                                                                                           \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.81it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 108.02it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 102.98it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.27it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.40it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 104.63it/s]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 87.58it/s]                                                                                           \n",
      "rtf_avg: 0.018: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 70.93it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_hyzLDiJQtwOEV', 'value': [[-1, 56460], [56740, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.019: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 74.25it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.65it/s]                                                                                          \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 92.32it/s]                                                                                           \n",
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 91.72it/s]                                                                                           \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 97.51it/s]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_jWKsmgBDTvykv', 'value': [[-1, 59540], [59820, -1]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 96.82it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 104.20it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 101.64it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.00it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 105.29it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 103.43it/s]                                                                                          \n",
      "rtf_avg: 0.018: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 76.84it/s]                                                                                          \n",
      "rtf_avg: 0.017: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 79.20it/s]                                                                                          \n",
      "rtf_avg: 0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 99.02it/s]                                                                                           \n",
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 87.15it/s]                                                                                           \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 107.30it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.03it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 113.27it/s]                                                                                          \n",
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 113.42it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 109.86it/s]                                                                                          \n",
      "rtf_avg: 0.011: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 112.90it/s]                                                                                          \n",
      "rtf_avg: 0.021: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 122.81it/s]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_IYmTsXCGMDIOq', 'value': [[-1, 70450]]}]\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "chunk_size = 600 # ms\n",
    "model = AutoModel(model=\"fsmn-vad\", max_end_slience_time_abvc = 600)\n",
    "\n",
    "import soundfile\n",
    "\n",
    "wav_file = f\"{model.model_path}/example/vad_example.wav\"\n",
    "speech, sample_rate = soundfile.read(wav_file)\n",
    "chunk_stride = int(chunk_size * sample_rate / 1000)\n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((speech)-1)/chunk_stride+1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = speech[i*chunk_stride:(i+1)*chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size)\n",
    "    if len(res[0][\"value\"]):\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 13:04:34,864 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-04-25 13:04:39,004 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-04-25 13:04:39,563 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfbcecc5ef44ddcbd28a04d1de347a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.598 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.598 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from app.asr import ParaformerOffline\n",
    "\n",
    "para = ParaformerOffline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpara\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/wanghuan/audio_services/app/asr/offline.py:19\u001b[0m, in \u001b[0;36mParaformerOffline.run\u001b[0;34m(self, fp, batch_size_s, hotword)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, fp:\u001b[38;5;28mstr\u001b[39m, batch_size_s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, hotword\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhotword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhotword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/auto/auto_model.py:306\u001b[0m, in \u001b[0;36mAutoModel.generate\u001b[0;34m(self, input, input_len, **cfg)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(\u001b[38;5;28minput\u001b[39m, input_len\u001b[38;5;241m=\u001b[39minput_len, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg)\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_with_vad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/auto/auto_model.py:383\u001b[0m, in \u001b[0;36mAutoModel.inference_with_vad\u001b[0;34m(self, input, input_len, **cfg)\u001b[0m\n\u001b[1;32m    381\u001b[0m deep_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvad_kwargs, cfg)\n\u001b[1;32m    382\u001b[0m beg_vad \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 383\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvad_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvad_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m end_vad \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m#  FIX(gcf): concat the vad clips for sense vocie model for better aed\u001b[39;00m\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/auto/auto_model.py:345\u001b[0m, in \u001b[0;36mAutoModel.inference\u001b[0;34m(self, input, input_len, model, kwargs, key, **cfg)\u001b[0m\n\u001b[1;32m    343\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 345\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    347\u001b[0m         results \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/models/fsmn_vad_streaming/model.py:700\u001b[0m, in \u001b[0;36mFsmnVADStreaming.inference\u001b[0;34m(self, data_in, data_lengths, key, tokenizer, frontend, cache, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m audio_sample_i \u001b[38;5;241m=\u001b[39m audio_sample[i \u001b[38;5;241m*\u001b[39m chunk_stride_samples : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m chunk_stride_samples]\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# extract fbank feats\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m speech, speech_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mextract_fbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43maudio_sample_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msound\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrontend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrontend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrontend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_final\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m time3 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    708\u001b[0m meta_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract_feat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime3\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtime2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/utils/load_utils.py:216\u001b[0m, in \u001b[0;36mextract_fbank\u001b[0;34m(data, data_len, data_type, frontend, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         data_len\u001b[38;5;241m.\u001b[39mappend(data_i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    214\u001b[0m     data \u001b[38;5;241m=\u001b[39m pad_sequence(data_list, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# data: [batch, N]\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m data, data_len \u001b[38;5;241m=\u001b[39m \u001b[43mfrontend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_len, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    219\u001b[0m     data_len \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([data_len])\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/frontends/wav_frontend.py:419\u001b[0m, in \u001b[0;36mWavFrontendOnline.forward\u001b[0;34m(self, input, input_lengths, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    416\u001b[0m     batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    417\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe support to extract feature online only when the batch size is equal to 1 now\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 419\u001b[0m waveforms, feats, feats_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_fbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# input shape: B T D\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feats\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    425\u001b[0m     cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaveforms\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreserve_waveforms\u001b[39m\u001b[38;5;124m\"\u001b[39m], waveforms), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/data1/wanghuan/env/lib/python3.10/site-packages/funasr/frontends/wav_frontend.py:326\u001b[0m, in \u001b[0;36mWavFrontendOnline.forward_fbank\u001b[0;34m(self, input, input_lengths, cache, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fbank\u001b[39m(\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    323\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    324\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     frame_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_frame_num(\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_sample_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_shift_sample_length\n\u001b[1;32m    329\u001b[0m     )\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# update self.in_cache\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "para.run(np.array([[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "from funasr import AutoModel\n",
    "from app.audio_utils import resample_audio_librosa\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_fmsn():\n",
    "    return AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\",max_end_silence_time=800)\n",
    "\n",
    "@dataclass\n",
    "class FMSNVad:\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.model = load_fmsn()\n",
    "        self.cache = {}\n",
    "        self.timestamp = 0\n",
    "        \n",
    "    def run(self, speech_chunk, sample_rate:int = 16000, is_final:bool = False):\n",
    "        if not sample_rate == 16000:\n",
    "            speech_chunk = resample_audio_librosa(speech_chunk, sample_rate, 16000)\n",
    "            \n",
    "        chunk_seconds = int(len(speech_chunk) * 1000 // 16000)  # in milliseconds\n",
    "        speech_chunk = np.array(speech_chunk).astype(\"float32\") # convert to float32 type\n",
    "        self.timestamp += chunk_seconds\n",
    "        if len(speech_chunk) == 0:\n",
    "            return [{'value':[-1,self.timestamp]}]\n",
    "        \n",
    "        res = self.model.generate(\n",
    "            input=speech_chunk, \n",
    "            cache=self.cache, \n",
    "            is_final=is_final, \n",
    "            chunk_size=chunk_seconds\n",
    "        )\n",
    "        return res\n",
    "    \n",
    "    def vad(self, speech_chunk, sample_rate:int = 16000, is_final:bool = False):\n",
    "        res = self.run(speech_chunk, sample_rate, is_final)\n",
    "        # 最后一个vad段，是一个结束的vad段\n",
    "        \n",
    "        try:\n",
    "            if res[0]['value'][-1][-1] >=0:\n",
    "                return True\n",
    "        except:\n",
    "            return False\n",
    "        \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 16:01:49,348 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7907c8728b1b45b6abeefe5f2e31b68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/8.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fmsn = FMSNVad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
